# Benchmark configuration for comparing Evidently drift detection with other methods

# Dataset configurations
[[datasets]]
    name      = "gaussian_drift"
    source    = "generator"
    generator = "gaussian"
[[datasets.params]]
    n_samples_reference = 1000
    n_samples_current   = 1000
    n_features          = 5
    drift_features      = [0, 2]
    shift_size          = 0.5

[[datasets]]
    name      = "categorical_drift"
    source    = "generator"
    generator = "categorical"
[[datasets.params]]
    n_samples_reference = 1000
    n_samples_current   = 1000
    n_features          = 3
    drift_features      = [0]
    probability_shift   = 0.2

[[datasets]]
    name   = "adult_dataset"
    source = "real"
[[datasets.params]]
    test_size      = 0.3
    random_state   = 42
    drift_features = ["age", "education"]

# Detector configurations
[[detectors]]
    name   = "evidently_data_drift"
    params = { drift_share_threshold = 0.3, test_threshold = 0.05 }

[[detectors]]
    name   = "evidently_data_quality"
    params = { drift_threshold = 0.05 }

[[detectors]]
    name   = "alibi_mmd"
    params = { p_val = 0.05, kernel = "rbf" }

    # Evaluation metrics
    metrics = [
        "accuracy",
        "precision",
        "recall",
        "f1",
        "execution_time",
        "memory_usage",
    ]

    # Experiment settings
    repetitions  = 3
    random_state = 42


# Visualization settings
[visualization]
    output_path    = "./results/evidently_comparison"
    formats        = ["png", "pdf"]
    include_tables = true
    dpi            = 300
    style          = "seaborn-v0_8-whitegrid"
