# Benchmark Configuration Example

[metadata]
    name        = "Example Drift Detection Benchmark"
    description = "A simple benchmark to demonstrate the capabilities of drift-benchmark"
    author      = "Drift Benchmark Team"
    date        = "2025-06-18"
    version     = "0.1.0"

[settings]
    seed                 = 42
    n_runs               = 5
    cross_validation     = true
    cv_folds             = 3
    timeout_per_detector = 300 # seconds

[data]
# Dataset configurations
[[data.datasets]]
    name           = "synthetic_gradual_drift"
    type           = "synthetic"
    n_samples      = 5000
    n_features     = 20
    drift_type     = "gradual"
    drift_position = 0.5
    noise          = 0.05

[[data.datasets]]
    name           = "synthetic_sudden_drift"
    type           = "synthetic"
    n_samples      = 5000
    n_features     = 20
    drift_type     = "sudden"
    drift_position = 0.6
    noise          = 0.05

[[data.datasets]]
    name          = "real_weather"
    type          = "file"
    path          = "datasets/weather.csv"
    target_column = "RainTomorrow"
    drift_column  = "date"
    train_size    = 0.3

[detectors]
# List of detectors to evaluate
[[detectors.algorithms]]
    name       = "DDM"
    library    = "skmultiflow"
    parameters = { warning_level = 2.0, drift_level = 3.0 }

[[detectors.algorithms]]
    name       = "ADWIN"
    library    = "skmultiflow"
    parameters = { delta = 0.002 }

[[detectors.algorithms]]
    name       = "KSWIN"
    library    = "skmultiflow"
    parameters = { alpha = 0.005, window_size = 100 }

[[detectors.algorithms]]
    name       = "PageHinkley"
    library    = "skmultiflow"
    parameters = { min_instances = 30, delta = 0.005, threshold = 50 }

[metrics]
    # Evaluation metrics
    metrics = [
        "detection_delay",
        "false_positive_rate",
        "false_negative_rate",
        "f1_score",
        "computation_time",
    ]

[output]
    save_results  = true
    results_dir   = "results/example_benchmark"
    visualization = true
    plots         = ["roc_curve", "delay_distribution", "performance_comparison"]
    export_format = ["csv", "json"]
    log_level     = "info"
